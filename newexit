from kfp import dsl
from kfp import compiler
from kubernetes.client import models as k8s
import os 
import yaml
import time
from jinja2 import Template

# Define a shared volume for storing task statuses
shared_volume = dsl.PipelineVolume(volume=k8s.V1Volume(
        name="shared-volume",
        empty_dir=k8s.V1EmptyDirVolumeSource()))

env_vars = {{ environment_vars }}
input_params = {{ input_params }}
resources = {{ resources }}
project_namespace = "{{ kubernetes_namespace }}"
efs_pvc = "{{ pvc }}"
jar_name = "{{ jar_name }}"
spark_enabled = "{{spark_enabled}}"
env_name = "{{ env_name }}"

if spark_enabled.upper() == 'TRUE':
  spark_tasks_params = {{ spark_tasks_params | tojson }}
  role_path = "{{ template_path }}"
  jinja_path = f"{role_path}spark_manifest_template.j2"
  with open(jinja_path, 'r') as file:
    spark_manifest_template = Template(file.read())

def spark_cleanup_task(driver_pod_name: str, stage_name: str):
    return dsl.ContainerOp(
        name=f"{stage_name}-spark-driver-cleanup",
        image="{{ image }}",
        command=["/bin/bash", "-c"],
        arguments=[
            """
            echo "Cleaning up Spark driver pod: $0"
            /home/kfp-user/bin/kubectl delete pod $0 --ignore-not-found=true
            """,
            driver_pod_name
        ]
    )

{% for stage_list in stages %}
{% for stage in stage_list %}
def {{ stage | replace("-","_") }}(
    {% for param in input_params.keys() %}{{ param }}{% if not loop.last %}, {% endif %}{% endfor %}):
    {% if resources[stage]['operator'] == 'pod' %}
    ...  # Pod logic unchanged
    return op
    {% endif %}

    {% if resources[stage]['operator'] == 'spark' %}
    ...  # Spark submission and logs unchanged
    fetch_spark_logs.after(submit_spark_job)
    return submit_spark_job, fetch_spark_logs, submit_spark_job.outputs['driver_pod_name']
    {% endif %}
{% endfor %}
{% endfor %}

@dsl.pipeline(
    name='{{ pipeline_name }}',
    description = '{{ pipeline_description }}'
)
def pipeline(
    {% for param in input_params.keys() %}{{ param }}{% if not loop.last %}, {% endif %}{% endfor %}):
    stages = {{ stages | tojson }}
    previous_stage_tasks = []

    for stage in stages:
        parallel_tasks = []

        for task_name in stage:
            task_function_name = f"{task_name.replace('-','_')}"
            task_output = globals()[task_function_name](
                {% for param in input_params.keys() %}{{ param }}{% if not loop.last %}, {% endif %}{% endfor %}
            )

            if isinstance(task_output, tuple) and len(task_output) == 3:
                task, fetch_spark_logs, driver_pod_name = task_output
                cleanup_task = spark_cleanup_task(driver_pod_name=driver_pod_name, stage_name=task_name)
                with dsl.ExitHandler(cleanup_task):
                    fetch_spark_logs.after(task)
                parallel_tasks.append(fetch_spark_logs)
            elif isinstance(task_output, tuple):
                task, fetch_spark_logs = task_output
                parallel_tasks.append(fetch_spark_logs)
            else:
                task = task_output

            if resources[task_name]['operator'] == 'pod':
                task.execution_options.caching_strategy.max_cache_staleness = "P0D"
            task.set_caching_options(False)
            parallel_tasks.append(task)

            if previous_stage_tasks:
                for prev_task in previous_stage_tasks:
                    task.after(prev_task)
                    if isinstance(task_output, tuple) and len(task_output) >= 2:
                        fetch_spark_logs.after(task)

        previous_stage_tasks = parallel_tasks

    dsl.get_pipeline_conf().set_ttl_seconds_after_finished(300)

compiler.Compiler().compile(pipeline, '{{pipeline_name}}_{{ run_name }}.yaml')
